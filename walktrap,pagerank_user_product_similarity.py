# -*- coding: utf-8 -*-
"""Walktrap,PageRank_User_Product_Similarity.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h2roKjToVIrox8ImRfvJS2Mq5dDEsyXH
"""

!pip install python-igraph cairocffi

# Commented out IPython magic to ensure Python compatibility.
import re
import pandas as pd
import numpy as np
import bs4
import requests
import spacy
from spacy import displacy
nlp = spacy.load('en_core_web_sm')

import itertools
import networkx as nx

import matplotlib.pyplot as plt
from tqdm import tqdm
import cairocffi
import igraph

pd.set_option('display.max_colwidth', 200)
# %matplotlib inline
nlp = spacy.load('en_core_web_sm')

def jaccard_similarity(Productlist1, Productlist2):
    s1 = set(Productlist1)
    s2 = set(Productlist2)
    return float(len(s1.intersection(s2)) / len(s1.union(s2)))

dataset = pd.read_csv('Final_data_search.csv',na_filter='NaN',na_values='NaN')

search_term = [ term for term in dataset['Search_Term'] ]
course_list = [ course for course in dataset['Course_Clicked']]
user_list = [ user for user in dataset['User_ID']]

def cleaner_function(search_term):
  for index,term in enumerate(search_term):
    if type(term)!=str or term == np.nan or type(term)==float or type(term)==int :
      search_term.pop(index)
      course_list.pop(index)
      user_list.pop(index)
  return search_term
search_term = cleaner_function(search_term)
search_term.remove(np.nan)

#Search term to product Relation Data structure 
Product_list_dict = dict()
for index,term in enumerate(search_term):
  Product_list_dict[term] = Product_list_dict.get(term,[])
  if type(course_list[index]) == str and term != np.nan and type(term)!=float and type(term)!=int:
    Product_list_dict[term].append(course_list[index])
    
Product_list = {k: v for k, v in Product_list_dict.items() if v != []}

#User id to product relation data structure
User_Product_list_dict = dict()
for index,user in enumerate(user_list):
  User_Product_list_dict[user] = User_Product_list_dict.get(user,[])
  if type(course_list[index]) == str and user != np.nan and type(user)!=float:
    User_Product_list_dict[user].append(course_list[index])

User_Product_list = {k: v for k, v in User_Product_list_dict.items() if v != []}



products=set()
for course_list in Product_list.values():
  courses=set(course_list)
  products = products.union(courses)
Product_set = list(products)

subset = dict(itertools.islice(Product_list.items(),len(Product_list.items())))

kg_df = []
for x_element in subset.keys():
  for y_element in subset.keys():
    jaccard = jaccard_similarity(subset[x_element],subset[y_element])
    kg_df.append([x_element,y_element,jaccard])



#Plotting Section

# G = nx.DiGraph()
# G.add_nodes_from(subset.keys())
# G.add_weighted_edges_from(kg_df)

# elarge=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] >=0.3 and d['weight'] !=1]
# esmall=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] <0.3 and d['weight']!=0]

# plt.figure(figsize=(16,16))
# pos=nx.shell_layout(G) # positions for all nodes
# nx.draw_networkx_nodes(G,pos,node_size=22)
# nx.draw_networkx_edges(G,pos,edgelist=elarge,width=1,)
# # nx.draw_networkx_edges(G,pos,edgelist=esmall,width=1,alpha=0.5,edge_color='#76ac41')
# nx.draw_networkx_labels(G,pos,font_size=12,font_family='sans-serif')
# pr = nx.pagerank(G,alpha=0.85)
# plt.axis('off')
# plt.show()

# plt.figure(figsize=(16,16))
# nx.draw_networkx_nodes(G,pos,node_size=20)
# nx.draw_networkx_edges(G,pos,edgelist=esmall,width=1,alpha=0.5,edge_color='#76ac41')
# nx.draw_networkx_labels(G,pos,font_size=12,font_family='sans-serif')
# plt.axis('off')
# plt.show()





#Walktrap Implementaion

kg = []
for edge in kg_df:
  if edge[2] == 0.0 or edge[2]==1.0 :
    pass
  else:
    kg.append(edge)

Gm = igraph.Graph.TupleList(kg, directed = True, edge_attrs = ['weight'])

mylayout = Gm.layout_fruchterman_reingold()
wtrap = Gm.community_walktrap(weights=Gm.es["weight"], steps = 5)
clust=wtrap.as_clustering()

print(clust)

# visual_style = {}
# visual_style["bbox"] = (700,600)
# # visual_style["vertex_label"] = Gm.vs["name"]
# visual_style['layout'] = mylayout
# visual_style['vertex_size'] = 11
# visual_style['edge_arrow_size'] = 0.4
# igraph.plot(clust,mark_groups = True,**visual_style)

containing_clusters = clust.subgraphs()

pagerank_arr = []
for subgraph in containing_clusters:
  temp_pagerank = subgraph.pagerank()
  temp = []
  for index,node in enumerate(subgraph.vs):
    temp.append([temp_pagerank[index],subgraph.vs[index]['name']])
  pagerank_arr.append(temp)

cluster_names = []
from operator import itemgetter
for index,cluster in enumerate(pagerank_arr):
  print(f'Cluster {index} ')
  cluster = sorted(cluster,key = itemgetter(0),reverse=True)
  print(f'Tag to be assigned =  {cluster[0][1]}')
  cluster_names.append([index,cluster[0][1]])
  print(cluster,sep='\n')

from collections import Counter
Product_frequency_dict={}
for search_term in Product_list:
  freq=dict(Counter(Product_list[search_term]))
  Product_frequency_dict[search_term]=freq

Course_list= {}
for product in Product_set:
  tagarray=[]
  for tag in cluster_names:
    temparray=[]
    for index,query in enumerate(pagerank_arr[tag[0]]):
      pro_sum = sum(Product_frequency_dict[query[1]].values())
      test = Product_frequency_dict[query[1]].get(product,0)
      Prob = test/pro_sum
      temparray.append(pagerank_arr[tag[0]][index][0]*Prob)
    tagarray.append([tag[1],sum(temparray)])
  Course_list[product]=tagarray

for course in Course_list:
  item_set = Course_list[course]
  tag = sorted(item_set,key=itemgetter(1),reverse=True)[0]
  print(f'Course -  {course} \t Tag - {tag[0]}')

similarity_vector=[]
for test_course in Course_list:
  for rest_course in Course_list:
    similarity=0
    if test_course == rest_course:
      pass
    else:
      res=[]
      for index,tag in enumerate(Course_list[test_course]):
        res.append(Course_list[test_course][index][1]*Course_list[rest_course][index][1])
      similarity = sum(res)
    similarity_vector.append([test_course,rest_course,similarity])

#User tagging model

from collections import Counter
User_Product_frequency_dict={}
for user in User_Product_list:
  freq=dict(Counter(User_Product_list[user]))
  User_Product_frequency_dict[user]=freq

User_tag_list={}
for user in User_Product_list:
  tagarray = []
  for tag in cluster_names:
    user_courses = User_Product_frequency_dict[user]
    total = sum(user_courses.values())
    user_courses_probability = []
    #Calculating Probabilty for user interest in courses
    for courses in user_courses:
      user_courses_probability.append([courses,user_courses[courses]/total])

    Course_score_set = []
    for course_set in user_courses_probability:
      course = course_set[0]
      product_tag_score = Course_list.get(course,[])
      for tag_score in product_tag_score:
        if tag_score[0]==tag[1]:
          score = tag_score[1]*course_set[1]
          Course_score_set.append(score)
    tagarray.append([tag[1],sum(Course_score_set)])
  User_tag_list[user] = tagarray

User_tags = {}
for users in User_tag_list:
  tag_set = User_tag_list[users]
  for tag in tag_set:
    if tag[1]>0:
      User_tags[users] = User_tags.get(users,[])
      User_tags[users].append(tag)

for user in User_tags:
  print('User - ',user)
  print('Assigned tags to user {} are'.format(user))
  for tag in User_tags[user]:
    print('Tag {} \t Tag score {:.6f}'.format(tag[0],tag[1]))
  print('\n')









#Rest probably not useful

#Rest probably not useful

#Rest probably not useful

#Rest probably not useful

labelProp = Gm.community_label_propagation(weights=Gm.es["weight"])
igraph.plot(labelProp,mark_groups = True,**visual_style)

print(labelProp)